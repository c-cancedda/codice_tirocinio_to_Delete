{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ETACONTRAENTE COMUNE PROVINCIA SESSO STATOCIVILE    CAP  ETAVEICOLO  \\\n",
      "0             49   D612        FI     M         NaN  50100           0   \n",
      "1             45   F257        MO     M         NaN  41100           1   \n",
      "2             53   D612        FI     F         NaN  50100           8   \n",
      "3             27   D611        PC     F         NaN  29017           3   \n",
      "4             52   D612        FI     M         NaN  50100           4   \n",
      "\n",
      "   POTENZA  CILINDRATA  VALORE  ... ASS TUT  tot_incidenti    km_totali  \\\n",
      "0      110        1968   30400  ...   0   0         5272.0  14563.04400   \n",
      "1       51        1242    7700  ...   0   1         2818.0  17271.77914   \n",
      "2       50         998       0  ...   1   0         5272.0  14563.04400   \n",
      "3      110        1968       0  ...   1   0          988.0  10514.14454   \n",
      "4       51        1229       0  ...   1   1         5272.0  14563.04400   \n",
      "\n",
      "   km_autostrada   km_urbani  parco_veicolare  popolazione_residente  \\\n",
      "0      417.89079  4724.35127         974655.0              1014423.0   \n",
      "1      207.22543  6313.48522         591297.0               700862.0   \n",
      "2      417.89079  4724.35127         974655.0              1014423.0   \n",
      "3      272.89658  3084.06655         242824.0               286758.0   \n",
      "4      417.89079  4724.35127         974655.0              1014423.0   \n",
      "\n",
      "   pil_totale  pil_pro_capite  \n",
      "0    112239.0         30500.0  \n",
      "1    153997.0         35300.0  \n",
      "2    112239.0         30500.0  \n",
      "3    153997.0         35300.0  \n",
      "4    112239.0         30500.0  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "accuracy :  1.0\n",
      "accuracy :  0.9541\n",
      "accuracy :  0.9204\n",
      "accuracy :  0.7745\n",
      "accuracy :  0.9323\n",
      "accuracy :  0.9298\n",
      "accuracy :  0.6229\n",
      "accuracy :  0.638\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rand\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "import make_province\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "def get_percent_full(col_name, df):\n",
    "    return len(df[df[col_name].isnull()][col_name])/len(df[col_name]) * 100.0\n",
    "\n",
    "def get_uniques(col_name, df):\n",
    "    return df[col_name].unique()\n",
    "\n",
    "\n",
    "province_df = make_province.generate_province_data().drop(columns=\"regione\", axis=1)\n",
    "ins_df = pd.read_csv(\"/datasets/extr.csv\", index_col=0)\n",
    "\n",
    "ins_df = ins_df.merge(province_df, how=\"left\", left_on=\"PROVINCIA\", right_on=\"id_provincia\" ).drop(columns=[\"id_provincia\"], axis=1)\n",
    "    \n",
    "print(ins_df.head())\n",
    "\n",
    "# colonne utilizzate dal dataset istat\n",
    "added_cols = ['tot_incidenti',\n",
    "'km_totali', 'km_autostrada', 'km_urbani', 'parco_veicolare',\n",
    "'popolazione_residente', 'pil_totale', 'pil_pro_capite']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# assegnazione di nan agli zeri privi di significato\n",
    "ins_df[\"POTENZA\"].replace(to_replace=0, value=np.nan, inplace=True)\n",
    "ins_df[\"VALORE\"].replace(to_replace=0, value=np.nan, inplace=True)\n",
    "ins_df[\"CILINDRATA\"].replace(to_replace=0, value=np.nan, inplace=True)\n",
    "\n",
    "# visualizzazione delle percentuali di valori assenti\n",
    "#for col_name in ins_df.columns.to_list():\n",
    "#    print(col_name, \" : \", get_percent_full(col_name, ins_df))\n",
    "\n",
    "\n",
    "# valorizzazione dei campi assenti con la media per una certa feature\n",
    "ins_df[\"POTENZA\"].fillna(ins_df[\"POTENZA\"].mean(), inplace=True  )\n",
    "ins_df[\"CILINDRATA\"].fillna(ins_df[\"CILINDRATA\"].mean(), inplace=True  )\n",
    "ins_df[\"VALORE\"].fillna(ins_df[\"VALORE\"].mean(), inplace=True  )\n",
    "ins_df[\"STATOCIVILE\"].fillna(\"NON_SPECIFICATO\", inplace=True  )\n",
    "\n",
    "\n",
    "\n",
    "# elementi della stessa categoria raggruppati sotto un' unica classe, in questo caso le chiavi sono mappate sui nuovi valori\n",
    "stato_mapping = { \"NUBILE\" : \"CELIBE\",\n",
    "                    \"CONIUGATA\" : \"CONIUGATO\",\n",
    "                    \"VEDOVA\" : \"VEDOVO\",\n",
    "                    \"DIVORZIATA\" : \"DIVORZIATO\",\n",
    "                    \"SEPARATA\" : \"SEPARATO\"}\n",
    "\n",
    "# rimpiazzamento dei campi con data chiave col valore corrispondente\n",
    "ins_df[\"STATOCIVILE\"].replace(to_replace=stato_mapping, inplace=True)\n",
    "\n",
    "\n",
    "for added_col  in added_cols:\n",
    "    ins_df[added_col].fillna(ins_df[added_col].mean(), inplace=True  )\n",
    "\n",
    "\n",
    "\n",
    "#for col_name in ins_df.columns.to_list():\n",
    "#    print(col_name, \" : \", get_percent_full(col_name, ins_df))\n",
    "\n",
    "    \n",
    "# test delle performance degli algoritmi a seguito dell' eliminazione di una o piu delle seguenti colonne\n",
    "#ins_df.drop(columns=\"VALORE\", axis=1, inplace=True)\n",
    "#ins_df.drop(columns=\"STATOCIVILE\", axis=1, inplace=True)\n",
    "#ins_df.drop(columns=\"ANTIFURTO\", axis=1, inplace=True)\n",
    "    \n",
    "continuous_columns = [\"ETACONTRAENTE\", \"ETAVEICOLO\", \"POTENZA\", \"CILINDRATA\", \"VALORE\"] + added_cols\n",
    "categorical_columns = [ \"COMUNE\",  \"PROVINCIA\", \"SESSO\", \"CAP\",\n",
    "                           \"ANTIFURTO\",\n",
    "                       \"ALIMENTAZIONE\", \"STATOCIVILE\" ]\n",
    "\n",
    "classes = [\"RC\", \"INC\", \"FUR\", \"ESP\", \"CRI\", \"EVN\", \"INF\", \"ASS\", \"TUT\" ]\n",
    "\n",
    "# standardizzazione feature a valori continui\n",
    "std = StandardScaler() \n",
    "ins_df[continuous_columns] = std.fit_transform(ins_df[continuous_columns])\n",
    "\n",
    "# one hot encoding delle colonne categoriche specificate\n",
    "ins_df = pd.get_dummies(ins_df, columns=categorical_columns )\n",
    "\n",
    "X = ins_df.drop(columns=classes, axis=1)\n",
    "\n",
    "to_predict = [\"INC\", \"FUR\", \"ESP\", \"CRI\", \"EVN\", \"INF\", \"ASS\", \"TUT\" ]\n",
    "\n",
    "# valutazione delle prestazioni dell' algoritmo per ciascuna colonna\n",
    "for col_to_predict in to_predict:\n",
    "    \n",
    "    y = ins_df[col_to_predict]\n",
    "\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "    '''\n",
    "    model = xgb.XGBClassifier(max_depth=4, n_estimators=2000, learning_rate=0.01, random_state=42)\n",
    "    '''\n",
    "    '''\n",
    "    model = GradientBoostingClassifier(loss=\"deviance\",\n",
    "                                    learning_rate=0.04, n_estimators=1000,\n",
    "                                    min_samples_split=2,\n",
    "                                    min_samples_leaf=1,\n",
    "                                    max_depth=3,\n",
    "                                    random_state=42)\n",
    "    \n",
    "    '''\n",
    "    #'''\n",
    "    model = DecisionTreeClassifier(criterion=\"entropy\",\n",
    "                                   max_depth=7)\n",
    "    #'''\n",
    "    '''\n",
    "    eoe_dtree = DecisionTreeClassifier(criterion=\"entropy\",\n",
    "                                   max_depth=6)\n",
    "    model = AdaBoostClassifier(base_estimator= eoe_dtree,\n",
    "                        n_estimators=200,\n",
    "                        learning_rate=0.05,\n",
    "                        random_state=42)\n",
    "    '''\n",
    "    '''\n",
    "    model = RandomForestClassifier(bootstrap=True, criterion=\"entropy\", max_depth=10,\n",
    "                                max_features=\"sqrt\", min_samples_leaf=1, min_samples_split=10,\n",
    "                                n_estimators=1000, n_jobs=-1, random_state=42)\n",
    "    '''\n",
    "    model.fit(x_train, y_train)\n",
    "    accuracy = model.score(x_test, y_test)\n",
    "    print(\"accuracy : \", accuracy)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
